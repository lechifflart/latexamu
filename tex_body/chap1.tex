\linenumbers
\chapter{ State of the art theory}
\chaptertoc{}

\section{Introduction on the many-body problem}
%generalities on theories that are the building blocks of our workflows
%what is ab initio
The system of interacting electrons and nuclei in a material is described by the following Hamiltonian :
\begin{align}
	\hat{H} = &- \sum_I \frac{\hbar^2}{2 M_I} \nabla^2_I + \frac{1}{2} \sum_{I\neq J} \frac{Z_I Z_J e^2}{\left| \RR_I - \RR_J \right|} \nonumber \\
	&- \frac{\hbar^2}{2m_e} \sum_i \nabla^2_i + \frac{1}{2} \sum_{i\neq j} \frac{e^2}{\left| \rr_i - \rr_j \right|} - \sum_{i,I} \frac{Z_I e^2}{\left|\rr_i - \RR_I \right|}
\end{align}
where capital indices refer to nuclei and lowercase indices refer to electrons. $Z_I$, $M_I$ and $\RR_I$ are the atomic number, the mass and the position in real space of nucleus $I$. In this thesis, unless explicitly specified, we will use the atomic units, that is $\hbar = m_e = e =\pi/\varepsilon_0 =1$.
The terms on the first line are the kinetic energy of the ions and the ion-ion interaction, respectively. On the second line we have the kinetic energy of electrons, that we will later denote $T_{ee}$, the electron-electron interaction $V_{ee}$ and finally the electron-nucleus interaction, which we will refer to as the external potential felt by electrons in equilibrium, $V_{ext}$. To greatly simplify this Hamiltonian, we use the Born-Oppenheimer approximation. It consists in considering the nuclei fixed, because their masses are much greater than those of the electrons. The Hamiltonian then reads :
\be
	\hat{H} = \hat{T_e} + \hat{V}_{ee} + \hat{V}_{ext}
\ee
The first and second term are universal for all systems.The peculiarities of any systems are included in the last term in the above equation.

\section{Density Functional Theory}
This theory is vastly used in solid-state physics and quantum chemistry. In this thesis, it will be the starting tool to compute structural and electronic properties of our systems. The idea behind \gls{DFT} is to replace the real system of interacting electrons by an auxiliary system of non-interacting particles evolving in an effective potential.

\gls{DFT} is a theory of the interacting electron system and is based on the work of Hohenberg and Kohn who stated and proved two fundamental theorems. \cite{hohenberg1964} The first one ensures there is a one-to-one correspondance between the electronic density and the external potential acting on the system. The second theorem states that the total energy of the system is a functional of the electronic density.
The total energy of a system of interacting electrons is written as :
\be
	E = \expval{\hat{H}}{\Psi} = \expval{\hat{T} + \hat{V}_{ee} }{\Psi} + \int d\rr v_{ext}(\rr)n(\rr)
\ee
By virtue of the Hohenberg and Kohn theorems, the total energy is a functional of the density and can be written as :
\be
 	E_{HK}[n] = F_{HK}[n] + \int d\rr v_{ext}(\rr)n(\rr)
	\label{eq:E_HK}
\ee
where $F_{HK}[n] = \la \hat{T} \ra + \la \hat{V}_{ee} \ra$ is a universal functional of the density, \emph{ie} the dependence on $n$ of the functional is the same for all systems. The ground-state energy $E = E_0$ is the minimum of the energy functional at the ground-state density $n=n_0$. To be able to compute these quantities, Kohn and Sham reformulated the problem into an auxiliary system of non-interacting particles, that has the same density as the real system.\cite{kohn1965} This reformulation is particularly helpful because it is possible to compute analytically the kinetic energy term. The only subtlety is that one needs to use the density \emph{matrix} rather than the electronic density, that is defined as the expectation value of the density operator $\hat{\delta}(\rr) = \sum_i^{N_{e}} \delta(\rr - \rr_i)$ :
\begin{align}
\begin{split}
	n(\rr) &= \int d^3r_1 ... d^3r_{N_{e}} \Psi^*(\rr_1,...,\rr_{N_{e}})
	\hat{\delta}(\rr) \Psi(\rr_1,...,\rr_{N_{e}}) \\
	&= N_{e}\int d^3r_2 ... d^3r_{N_{e}} \left| \Psi(\rr,\rr_2...,\rr_{N_{e}})\right|^2
\end{split}
\end{align}
This is related to the probability density of finding a particle at position $\rr$.
The expression for the total energy functional in \ref{eq:E_HK} can be rewritten as :
\be
	E_{KS}[n] = T_{ip}[n] + \int d\rr v_{ext}(\rr)n(\rr) + E_H[n] + E_{XC}[n]
\ee
where $T_{ip}$ is the kinetic energy of the independent particles with density $n$, $E_H$ is the Hartree energy, which is the classical electrostatic interaction :
\be
	E_H[n] = \int d\rr d\rr' \frac{n(\rr')n(\rr)}{\left|\rr - \rr' \right|}
	\label{eq:E_Hartree}
\ee
and $E_{XC}$ is the exchange-correlation energy functional defined as :
\be
	E_{XC}[n] = \langle \hat{T} \rangle - T_{ip} + \langle \hat{V}_{ee} \rangle - E_H.
\ee
It is the difference between the exact kinetic energy and $T_{ip}$ plus the difference between the exact electron-electron interaction and the Hartree energy functional. Hence it contains the quantum effects of exchange and correlation of fermions.

Since the auxiliary system is an ensemble of independent particles, one can write the so-called Kohn-Sham equations for each individual particle $i$ :
\be
 	\( -\frac{\nabla^2}{2} + v_{eff}(\rr)\) \psi_i(\rr) = \varepsilon_i \psi_i(\rr).
\ee
They are analogous to Schr√∂dinger equation for a particle evolving in a local effective potential $v_{eff}$, that we have yet to determine. Their solutions are the auxiliary system's eigenvalues $\varepsilon_i$ and the eigenvectors $\psi_i$ that are defined as :
\be
 	n(\rr) = \sum_i f_i \left| \psi_i\right|^2
\ee
where $f_i$ is the occupation number of state $i$. Using the fact that the total kinetic energy is independent of the density at fixed number of particles, we get :
\begin{align}
\begin{split}
	v_{eff}(\rr) &= v_{ext}(\rr) + \frac{\delta E_H[n]}{\delta n(\rr)} + \frac{\delta E_{xc}[n]}{\delta n(\rr)} \\
	&\equiv v_{ext}(\rr) + v_H([n],\rr) + v_{xc}([n],\rr).
\end{split}
\end{align}
At this point, we see that we have to solve the many-electron problem self-consistently. Indeed, the density is obtained by solving the Kohn-Sham equations which contain the effective potential. In turn, this potential depends on the density. In practice, one starts from a guess density and iterate over the self-consistent cycle until the quantities of interest vary less than an arbitrary threshold.

Up to now, \gls{DFT} is in principle an exact theory, as long as one can define an auxiliary system with the same density as the real system. However, there exists no analytical form of the exchange-correlation potential. Hence we will then have to resort to approximations to compute the density in practice.

The \textbf{\gls{LDA}} is the first one that we present, and that we used for most of the results in this thesis. It was proposed by Kohn and Sham \cite{kohn1965}. It consists in replacing the exchange-correlation energy density by the one of the homogeneous electron gas, which is local in the density :
\be
	E_{XC}^{LDA} [n] = \int d\rr \ \epsilon^{HEG}_{xc}(n(\rr))
\ee
The exchange energy density of the homogeneous electron gas is known : $\epsilon_X^{HEG}(n) = -\tfrac{3}{4}(\tfrac{3}{\pi}n)^{(1/3)}$, and the correlation energy density is obtained from interpolation of an accurate quantum Monte Carlo simulation \cite{ceperley1980ground} for various values of densities. The LDA is relatively simple and computationally inexpensive. It gives a satisfactory description of system with slowly-varying density, but also surprisingly good results for a larger range of materials. For instance, for layered materials such as hBN, the interlayer binding energies are rather accurate, due to the tendency of overbinding of the LDA which cancels the error induced by the lack of van der Waals interactions.

In the \textbf{\gls{GGA}} the exchange-correlation energy density contains an additional dependence in the gradient of the density :
\be
 	E_{XC}^{GGA} [n] = \int d\rr \ \epsilon^{GGA}_{xc}(n(\rr),\nabla n(\rr)).
\ee
There are many different ways of expressing the exchange-correlation energy density in this case. Some of the proposed approximated functionals include the exact exchange term or a fraction of it, and it is separated from the correlation term.
There are many more approximations going beyond LDA and GGA functionals that we will not detail here, as we did not use them for the DFT calculations in this thesis.\newline

In our work, the description of each and every electron of the crystal is not necessary. Indeed, for the range of energies we are interested in, the electrons that can be optically excited are the ones that occupied the highest valence shells. The core electrons of the first $s$ and $p$ shells are bound too strongly to the nuclei to be excited by a few electron-Volts incoming light. Hence, to simplify the system, we use pseudopotentials to avoid describing the core electrons.
Pseudopotentials solve the problem of the divergence of the Coulomb potential as $\rr  \to 0$, which leads to rapid oscillations in the wave functions of the valence orbitals.
Beyond a given cutoff radius $r_c$, pseudopotentials are constrained to be exactly equal to the true
potential. Below this radius, the pseudopotential does not diverge and assumes a finite value at $r=0$. This generates a pseudo-wave function which is smooth and does not oscillate below the cutoff radius. With this method, the Kohn-Sham eigenvalues remain unchanged, and the computationally demanding task of representing the oscillating wave function is eliminated.\newline

For real systems, the wave function of the crystal is an immensely complicated object whose analytical expression is out of reach. For computational purposes, one needs to represent it in a complete basis of the Hilbert space. Depending on the characteristics of the system, the choice of the basis functions is different.

In this thesis we study infinite, periodic crystals. A suitable basis for this case is the plane waves. It is based on the Bloch theorem, which states that the square modulus of the wave function of an electron has the same periodicity than the crystal potential :
\be
 	\phi_{j,\kk} (\rr) = u_j (\rr) e^{i\kk\cdot\rr}
\ee
The $u_j$ functions have the same periodicity as the lattice. They are the one we decompose into plane waves as such :
\be
 	u_j (\rr) = \sum_{\GG} c_{j,\GG} e^{i\GG \cdot \rr}
\ee
where $c_{j,\GG}$ are the coefficients of the plane waves basis, and the $\GG$ are the reciprocal lattice vectors. The plane waves expansion of the band $j$ follows :
\be
	\phi_{j,\kk} (\rr) = \sum_{\GG} c_{j,\kk+\GG} e^{i (\kk+\GG)\cdot \rr}
\ee
In principle all complete bases of the Hilbert space yield equal representation of the wave function. As it is impossible to numerically sample a Hilbert space with infinite dimension, one has to truncate the representation. Thus, one has to make sure enough basis functions are included in the expansion to have an accurate wave function.
In this case, we choose an energy cutoff $E_{cut}$ such that :
\be
	\frac{1}{2} \left| \kk+\GG \right|^2 \leq E_{cut}
\ee
One has to verify that the cutoff is high enough so that the results are accurate, but setting it too high would mean including more plane waves which would slow down the calculations. \newline

Density Functional Theory is often used as a reference for bandgaps and electronic dispersion calculations. One has to be careful when interpreting Kohn-Sham eigenvalues, because they do not bear any physical meaning. First, there is no guaranty that one can find an auxiliary system of non-interacting particles for any real system. Then, the excited states and bandgaps are not the physical ones. This is especially relevant if one wants to simulate optics experiments of semiconductors or insulators. Optical excitations are neutral excitations, in the sense that the excited electron does not leave the system and therefore can interact with the hole it left behind in the valence band. This interaction between a hole in a valence band and an excited electron in the conduction bands is not accurately accounted for in \gls{DFT}, as it is designed to compute total energy and electronic density of the \textit{groundstate}. For this reason, we will resort to a more refined theoretical framework to treat the electronic correlations and study the excited states.

%(Structure optimization ? Hellmann-Feynman theorem to compute the forces acting on atoms, compute the total energy, minimize both the forces and the total energy)

\section{Many-Body Perturbation Theory}
concept of quasiparticle
self-energy is difference between the independent particle energy and the quasiparticle energy (for the real part) ; the imaginary part is the inverse QP lifetime
define Green's function as electronic propagator
explain what we do in the next subsection; define G, derive its equation of motion, get $G_2$, nested dependence on higher-order GFs hence : resum with a self-energy. To compute self-energy, we need a cycle of equations with vertex, polarization etc; approximate self-energy $\Sigma = GW$ to simplify the Hedin's equations 
define screening
derive GW

\textbf{Derivation of GW approximation}
% First, define the Green's function
$x = (\rr,\sigma)$;
We consider a system of N interacting electrons. We will consider the effect of nucleus motion in a later section.
In the limit of large kinetic energy, adding or removing is instantaneous. Addition or removal energy are directly related to the electronic Green's function, defined as :
\begin{equation}
	iG(x,x') = \bra{0} \hat{T} \left[ \hat{\psi}(x)\hat{\psi}^\dagger(x') \right] \ket{0} \label{eq:GF}
\end{equation}
where $\ket{0}$ is the exact ground state of the N-electron system, $\hat{\psi}(x)$ is a field operator in Heisenberg representation which annihilates an electron at $x = (\rr,t)$ and T is the Wick's time-ordering operator. It ensures that the time variable increase from right to left. It gives $\hat{T}\left[ \hpsi(\rr t) \hpsidag(\rr 't') \right] = \theta(t-t') \hpsi(\rr t) \hpsidag(\rr 't') - \theta(t'-t)\hpsidag(\rr't')\hpsi(\rr t)$, where $\theta$ is the Heaviside function.  %Physically, probability of propagating an added or removed electron.

We shall make explicit the time dependence of every term appearing in \ref{eq:GF}. We start with the time evolution of the field operators. We recall some useful properties of the field operators for fermions in the Schr√∂dinger picture :
\begin{align}
\begin{split}
	\{ \hpsi(x),\hpsidag(x')\} &= \delta (x-x') \\
	\{ \hpsi(x),\hpsi(x') \} &= \{ \hpsidag(x),\hpsidag(x') \} = 0 \\
	n(x) &= \hpsidag(x)\hpsi(x)
\end{split}	
\end{align}
We start from the Hamiltonian for interacting electrons in second quantization:

\begin{align}
\begin{split}
 	\hat{H} &= \int dx_1 \ \hpsidag(x_1) h(x_1) \hpsi(x_1) + \frac{1}{2} \int\int dx_1 \  dx_2 \ \hpsidag(x_1) \hpsidag(x_2) v(x_1,x_2) \hpsi(x_2)\hpsi(x_1) \\
		&= \hat{H}_0 + \hat{H}_{int}
\end{split}
\end{align}
where $h$ is the single-particle Hamiltonian for non-interacting particles evolving in an external potential $v_{ext}$. The total Hamiltonian containing this plus the interaction term enters the Heisenberg equation of motion for an operator $\hat{O}$:
\begin{equation}
	i\frac{d}{d t}\hat{O}_H(t) = \hat{U}^\dagger_S(t) \left[ \hat{O}(t),\hat{H} \right] \hat{U}_S(t) + \hat{U}^\dagger_S(t) (i \frac{d}{dt} \hat{O}_S(t)) \hat{U}_S(t)
\end{equation}
where the subscript $H$ and $S$ denote respectively the Heisenberg and Schr√∂dinger pictures, and the transformation from one the latter to the former is given by :
\begin{align}
\begin{split}
	\hpsi_H(x,t) &= \hat{U}^\dagger_S(t) \hpsi_S(x) \hat{U}_S(t) \\
	\hpsidag_H(x,t) &= \hat{U}^\dagger_S(t) \hpsidag_S(x) \hat{U}_S(t)
\end{split}
\end{align}
and $\hat{U}_S(t) = \exp(-i\hat{H}t) $ is the time evolution operator. In the following we drop the subscript $H$ for the field operators, as their time dependence will be explicit. The Heisenberg equation of motion for the field operator is then :
\begin{equation}
	i\frac{d}{dt} \hpsi(x,t) = \hat{U}^\dagger_S(t) \left[ \hpsi(x),\hat{H} \right] \hat{U}_S(t)
\end{equation}
and similarly for $\hpsidag$. To compute the commutator, we split the two terms of the Hamiltonian and we use the identity 
\begin{equation}
	\left[ \hpsi(x),\hat{A}\hat{B} \right] = \{ \hpsi(x),\hat{A} \}\hat{B} -  \hat{A}\{ \hpsi(x), \hat{B} \}
\end{equation}
where we take
\begin{align} 
\begin{split}
	\hat{A} &= \hpsidag(x_1) \\
	\hat{B} &= h(x_1) \hpsi(x_1)
\end{split}
\end{align}
Since $\{\hpsi(x),\hat{B}\} = 0$, then 
\begin{equation}
	\left[ \hpsi(x),\hat{H}_0\right] = h(x) \hpsi(x)
\end{equation}
Now we notice that the second term in the commutator contains 
\begin{align}
\begin{split}
	\left[ \hpsi(x), \hpsidag(x_1)\hpsidag(x_2)\hpsi(x_2)\hpsi(x_1) \right] &= \left[ \hpsi(x),\hpsidag(x_1)\hpsidag(x_2) \right] \hpsi(x_2)\hpsi(x_1) \\
	&= \left( \hpsidag(x_1) \delta(x_1-x_2) + \hpsidag(x_2)\delta(x-x_1) \right) \hpsi(x_2)\hpsi(x_1).
\end{split}
\end{align}
Therefore, 
\begin{align}
\begin{split}
	\left[ \hpsi(x),\hat{H}_{int} \right] &= \frac{1}{2} \int dx_1 \hpsidag(x_1)\hpsi(x)\hpsi(x_1) v(x,x_1) + \frac{1}{2} \int dx_2 \hpsidag(x_2)\hpsi(x_2)\hpsi(x) v(x,x_2) \\
	&= \int dx_2 v(x,x_2) \hpsidag(x_1) \hpsi(x_2) \hpsi(x)
\end{split}
\end{align}
where in the second line we used the symmetry property of the Coulomb interaction $v(x,x') = v(x',x)$.
Finally, with the compact notation $1 \equiv (\rr_1, \sigma, t_1)$, we get the equations of motion for the field operators :
\begin{align}
\begin{split}
	\frac{\partial}{\partial t_1} \hpsi(1) &= -i \left[ h(1) + \int d3 v(1,3) \hpsidag(3)\hpsi(3) \right] \hpsi(1) \\
	\frac{\partial}{\partial t_2} \hpsidag(2) &= i \left[ h(2)\hpsidag(2) + \hpsidag(2) \int d3 v(2,3) \hpsidag(3)\hpsi(3) \right]
\end{split}
\end{align}






% This was from Aryasetiawwan Gunnarsson
%
% We start with the Hamiltonian of the electronic system in second quantization :
% \be 
% 	\hat{H} = \int d^3r \ \hpsidag(x) h_0(x) \hpsi(x) + \frac{1}{2} \int d^3r \  d^3r' \ \hpsidag(x) \hpsidag(x') v(\rr - \rr') \hpsi(x')\hpsi(x)  
% \ee
% where $h_0$ contains the energy of the single, non-interacting electron evolving in a local external potential, and the second term on right-hand side is the electron-electron interaction. In the Heisenberg picture, the time-dependence of the field operators is given by :
% \be 
% 	\hpsi(\rr t) = e^{it\hat{H}} \hpsi(\rr t) e^{-it\hat{H}}
% \ee
% Hence we get the Heisenberg equation of motion for the field operator :
% \be 
% 	i\frac{\partial \hpsi(x)}{\partial t} = \left[ \hpsi(x),\hat{H}\right]
% \ee
% With the Green's function defined above in \ref{eq:GF}, the equation of motion for the Green's function simply follows :
% \be 
% 	\left[ i\frac{\partial }{\partial t } - h_0(x) \right] G(x,x') - \int dx'' M(x,x'') G(x'',x') = \delta(x-x').
% \ee
% The mass operator $M$ is defined as :
% \begin{align}
% \begin{split}
% 	\int dx_1 \ M(x,x_1) G(x_1,x') = &-i \int d^3r_1 \ v(\rr - \rr_1)\\ \nonumber
% 	&\times \bra{0} T\left[ \hpsidag(\rr_1 t)\hpsi(\rr_1 t) \hpsi(\rr t)\hpsidag (\rr',t') \right] \ket{0}
% \end{split}
% \end{align}
% The term on the second line is a special case of a two particle Green's function :
% \begin{equation}
% 	G_2(1,2,3,4) = i^2 \bra{0} T \left[ \hpsi(1)\hpsi(3)\hpsidag(2)\hpsidag(4) \right] \ket{0}
% \end{equation}
% At this point it is convenient to adopt the short-hand notation $1\equiv x_1 = (\rr_1 t_1)$ and $2\equiv x_2 = (\rr_2 t_2)$ and so on. 

% To proceed with the derivation of the self-energy, we will follow Schwinger's functional derivative method \textcolor{red}{Maybe read Schwinger and cite it :)}. We will introduce an external perturbation, in the form of a time-dependent field $\varphi(\rr t)$ that we will later set to 0 once the self-energy is obtained. We have to switch from Heisenberg to the (Dirac) interaction picture, where :
% \begin{equation}
% 	\ket{\Psi_D(\rr t)} = \hat{U}(t,t_0) \ket{\Psi_D(\rr t_0)}
% \end{equation}
% where $\hat{U}$ is the time evolution operator :
% \begin{equation}
% 	\hat{U}(t,t_0) = T \exp\left[ -i \int_{t_0}^t d\tau \ \hat{\varphi}(\tau) \right]
% \end{equation}
% \begin{equation}
% 	\hat{\varphi}(\tau) = \int d^3r \ \varphi(\rr,\tau) \hpsidag_D(\rr,\tau) \hpsi_D (\rr,\tau)
% \end{equation}
% Note that this interaction-picture field operator obeys the same equation of motion as the unperturbed Heisenberg operator :
% \begin{equation}
% 	i\frac{\partial}{\partial t} \hpsi_D = \left[ \hpsi_D,\hat{H}(\varphi=0)\right]
% \end{equation}
% where we recall the relationship between the two pictures :
% \begin{equation}
% 	\hpsi(\rr t) = \hat{U}^\dagger(t,0) \hpsi_D(\rr,t)\hat{U}(t,0).
% \end{equation}
% We can now write the Green's function using the $\hat{U}$ operator :
% \begin{equation}
% 	iG(1,2) = \frac{\bra{0}T\left[ \hat{U}(\infty,-\infty) \hpsi_D(1) \hpsidag_D(2)\right] \ket{0}}{\bra{0}\hat{U}(\infty,-\infty)\ket{0}}
% \end{equation}
% functional derivative of G ; try to understand the formula in Aryasetiawan

\linenumbers
\chapter{ State of the art theory}
\chaptertoc{}

\section{Introduction on the many-body problem}
%generalities on theories that are the building blocks of our workflows
%what is ab initio
The system of interacting electrons and nuclei in a material is described by the following Hamiltonian :
\begin{align}
	\hat{H} = &- \sum_I \frac{\hbar^2}{2 M_I} \nabla^2_I + \frac{1}{2} \sum_{I\neq J} \frac{Z_I Z_J e^2}{\left| \RR_I - \RR_J \right|} \nonumber \\
	&- \frac{\hbar^2}{2m_e} \sum_i \nabla^2_i + \frac{1}{2} \sum_{i\neq j} \frac{e^2}{\left| \rr_i - \rr_j \right|} - \sum_{i,I} \frac{Z_I e^2}{\left|\rr_i - \RR_I \right|}
\end{align}
where capital indices refer to nuclei and lowercase indices refer to electrons. $Z_I$, $M_I$ and $\RR_I$ are the atomic number, the mass and the position in real space of nucleus $I$. In this thesis, unless explicitly specified, we will use the atomic units, that is $\hbar = m_e = e =\pi/\varepsilon_0 =1$.
The terms on the first line are the kinetic energy of the ions and the ion-ion interaction, respectively. On the second line we have the kinetic energy of electrons, that we will later denote $T_{ee}$, the electron-electron interaction $V_{ee}$ and finally the electron-nucleus interaction, which we will refer to as the external potential felt by electrons in equilibrium, $V_{ext}$. To greatly simplify this Hamiltonian, we use the Born-Oppenheimer approximation. It consists in considering the nuclei fixed, because their masses are much greater than those of the electrons. The Hamiltonian then reads :
\be
	\hat{H} = \hat{T_e} + \hat{V}_{ee} + \hat{V}_{ext}
\ee
The first and second term are universal for all systems.The peculiarities of any systems are included in the last term in the above equation.

\section{Density Functional Theory}
This theory is vastly used in solid-state physics and quantum chemistry. In this thesis, it will be the starting tool to compute structural and electronic properties of our systems. The idea behind \gls{DFT} is to replace the real system of interacting electrons by an auxiliary system of non-interacting particles evolving in an effective potential.

\gls{DFT} is a theory of the interacting electron system and is based on the work of Hohenberg and Kohn who stated and proved two fundamental theorems. \cite{hohenberg1964} The first one ensures there is a one-to-one correspondance between the electronic density and the external potential acting on the system. The second theorem states that the total energy of the system is a functional of the electronic density.
The total energy of a system of interacting electrons is written as :
\be
	E = \expval{\hat{H}}{\Psi} = \expval{\hat{T} + \hat{V}_{ee} }{\Psi} + \int d\rr v_{ext}(\rr)n(\rr)
\ee
By virtue of the Hohenberg and Kohn theorems, the total energy is a functional of the density and can be written as :
\be
 	E_{HK}[n] = F_{HK}[n] + \int d\rr v_{ext}(\rr)n(\rr)
	\label{eq:E_HK}
\ee
where $F_{HK}[n] = \la \hat{T} \ra + \la \hat{V}_{ee} \ra$ is a universal functional of the density, \emph{ie} the dependence on $n$ of the functional is the same for all systems. The ground-state energy $E = E_0$ is the minimum of the energy functional at the ground-state density $n=n_0$. To be able to compute these quantities, Kohn and Sham reformulated the problem into an auxiliary system of non-interacting particles, that has the same density as the real system.\cite{kohn1965} This reformulation is particularly helpful because it is possible to compute analytically the kinetic energy term. The only subtlety is that one needs to use the density \emph{matrix} rather than the electronic density, that is defined as the expectation value of the density operator $\hat{\delta}(\rr) = \sum_i^{N_{e}} \delta(\rr - \rr_i)$ :
\begin{align}
\begin{split}
	n(\rr) &= \int d^3r_1 ... d^3r_{N_{e}} \Psi^*(\rr_1,...,\rr_{N_{e}})
	\hat{\delta}(\rr) \Psi(\rr_1,...,\rr_{N_{e}}) \\
	&= N_{e}\int d^3r_2 ... d^3r_{N_{e}} \left| \Psi(\rr,\rr_2...,\rr_{N_{e}})\right|^2
\end{split}
\end{align}
This is related to the probability density of finding a particle at position $\rr$.
The expression for the total energy functional in \ref{eq:E_HK} can be rewritten as :
\be
	E_{KS}[n] = T_{ip}[n] + \int d\rr v_{ext}(\rr)n(\rr) + E_H[n] + E_{XC}[n]
\ee
where $T_{ip}$ is the kinetic energy of the independent particles with density $n$, $E_H$ is the Hartree energy, which is the classical electrostatic interaction :
\be
	E_H[n] = \int d\rr d\rr' \frac{n(\rr')n(\rr)}{\left|\rr - \rr' \right|}
	\label{eq:E_Hartree}
\ee
and $E_{XC}$ is the exchange-correlation energy functional defined as :
\be
	E_{XC}[n] = \langle \hat{T} \rangle - T_{ip} + \langle \hat{V}_{ee} \rangle - E_H.
\ee
It is the difference between the exact kinetic energy and $T_{ip}$ plus the difference between the exact electron-electron interaction and the Hartree energy functional. Hence it contains the quantum effects of exchange and correlation of fermions.

Since the auxiliary system is an ensemble of independent particles, one can write the so-called Kohn-Sham equations for each individual particle $i$ :
\be
 	\( -\frac{\nabla^2}{2} + v_{eff}(\rr)\) \psi_i(\rr) = \varepsilon_i \psi_i(\rr).
\ee
They are analogous to Schrödinger equation for a particle evolving in a local effective potential $v_{eff}$, that we have yet to determine. Their solutions are the auxiliary system's eigenvalues $\varepsilon_i$ and the eigenvectors $\psi_i$ that are defined as :
\be
 	n(\rr) = \sum_i f_i \left| \psi_i\right|^2
\ee
where $f_i$ is the occupation number of state $i$. Using the fact that the total kinetic energy is independent of the density at fixed number of particles, we get :
\begin{align}
\begin{split}
	v_{eff}(\rr) &= v_{ext}(\rr) + \frac{\delta E_H[n]}{\delta n(\rr)} + \frac{\delta E_{xc}[n]}{\delta n(\rr)} \\
	&\equiv v_{ext}(\rr) + v_H([n],\rr) + v_{xc}([n],\rr).
\end{split}
\end{align}
At this point, we see that we have to solve the many-electron problem self-consistently. Indeed, the density is obtained by solving the Kohn-Sham equations which contain the effective potential. In turn, this potential depends on the density. In practice, one starts from a guess density and iterate over the self-consistent cycle until the quantities of interest vary less than an arbitrary threshold.

Up to now, \gls{DFT} is in principle an exact theory, as long as one can define an auxiliary system with the same density as the real system. However, there exists no analytical form of the exchange-correlation potential. Hence we will then have to resort to approximations to compute the density in practice.

The \textbf{\gls{LDA}} is the first one that we present, and that we used for most of the results in this thesis. It was proposed by Kohn and Sham \cite{kohn1965}. It consists in replacing the exchange-correlation energy density by the one of the homogeneous electron gas, which is local in the density :
\be
	E_{XC}^{LDA} [n] = \int d\rr \ \epsilon^{HEG}_{xc}(n(\rr))
\ee
The exchange energy density of the homogeneous electron gas is known : $\epsilon_X^{HEG}(n) = -\tfrac{3}{4}(\tfrac{3}{\pi}n)^{(1/3)}$, and the correlation energy density is obtained from interpolation of an accurate quantum Monte Carlo simulation \cite{ceperley1980ground} for various values of densities. The LDA is relatively simple and computationally inexpensive. It gives a satisfactory description of system with slowly-varying density, but also surprisingly good results for a larger range of materials. For instance, for layered materials such as hBN, the interlayer binding energies are rather accurate, due to the tendency of overbinding of the LDA which cancels the error induced by the lack of van der Waals interactions.

In the \textbf{\gls{GGA}} the exchange-correlation energy density contains an additional dependence in the gradient of the density :
\be
 	E_{XC}^{GGA} [n] = \int d\rr \ \epsilon^{GGA}_{xc}(n(\rr),\nabla n(\rr)).
\ee
There are many different ways of expressing the exchange-correlation energy density in this case. Some of the proposed approximated functionals include the exact exchange term or a fraction of it, and it is separated from the correlation term.
There are many more approximations going beyond LDA and GGA functionals that we will not detail here, as we did not use them for the DFT calculations in this thesis.\newline

In our work, the description of each and every electron of the crystal is not necessary. Indeed, for the range of energies we are interested in, the electrons that can be optically excited are the ones that occupied the highest valence shells. The core electrons of the first $s$ and $p$ shells are bound too strongly to the nuclei to be excited by a few electron-Volts incoming light. Hence, to simplify the system, we use pseudopotentials to avoid describing the core electrons.
Pseudopotentials solve the problem of the divergence of the Coulomb potential as $\rr  \to 0$, which leads to rapid oscillations in the wave functions of the valence orbitals.
Beyond a given cutoff radius $r_c$, pseudopotentials are constrained to be exactly equal to the true
potential. Below this radius, the pseudopotential does not diverge and assumes a finite value at $r=0$. This generates a pseudo-wave function which is smooth and does not oscillate below the cutoff radius. With this method, the Kohn-Sham eigenvalues remain unchanged, and the computationally demanding task of representing the oscillating wave function is eliminated.\newline

For real systems, the wave function of the crystal is an immensely complicated object whose analytical expression is out of reach. For computational purposes, one needs to represent it in a complete basis of the Hilbert space. Depending on the characteristics of the system, the choice of the basis functions is different.

In this thesis we study infinite, periodic crystals. A suitable basis for this case is the plane waves. It is based on the Bloch theorem, which states that the square modulus of the wave function of an electron has the same periodicity than the crystal potential :
\be
 	\phi_{j,\kk} (\rr) = u_j (\rr) e^{i\kk\cdot\rr}
\ee
The $u_j$ functions have the same periodicity as the lattice. They are the one we decompose into plane waves as such :
\be
 	u_j (\rr) = \sum_{\GG} c_{j,\GG} e^{i\GG \cdot \rr}
\ee
where $c_{j,\GG}$ are the coefficients of the plane waves basis, and the $\GG$ are the reciprocal lattice vectors. The plane waves expansion of the band $j$ follows :
\be
	\phi_{j,\kk} (\rr) = \sum_{\GG} c_{j,\kk+\GG} e^{i (\kk+\GG)\cdot \rr}
\ee
In principle all complete bases of the Hilbert space yield equal representation of the wave function. As it is impossible to numerically sample a Hilbert space with infinite dimension, one has to truncate the representation. Thus, one has to make sure enough basis functions are included in the expansion to have an accurate wave function.
In this case, we choose an energy cutoff $E_{cut}$ such that :
\be
	\frac{1}{2} \left| \kk+\GG \right|^2 \leq E_{cut}
\ee
One has to verify that the cutoff is high enough so that the results are accurate, but setting it too high would mean including more plane waves which would slow down the calculations. \newline

Density Functional Theory is often used as a reference for bandgaps and electronic dispersion calculations. One has to be careful when interpreting Kohn-Sham eigenvalues, because they do not bear any physical meaning. First, there is no guaranty that one can find an auxiliary system of non-interacting particles for any real system. Then, the excited states and bandgaps are not the physical ones. This is especially relevant if one wants to simulate optics experiments of semiconductors or insulators. Optical excitations are neutral excitations, in the sense that the excited electron does not leave the system and therefore can interact with the hole it left behind in the valence band. This interaction between a hole in a valence band and an excited electron in the conduction bands is not accurately accounted for in \gls{DFT}, as it is designed to compute total energy and electronic density of the \textit{groundstate}. For this reason, we will resort to a more refined theoretical framework to treat the electronic correlations and study the excited states.

%(Structure optimization ? Hellmann-Feynman theorem to compute the forces acting on atoms, compute the total energy, minimize both the forces and the total energy)

\section{Many-Body Perturbation Theory}
% zero temperature
% concept of quasiparticle
% self-energy is difference between the independent particle energy and the quasiparticle energy (for the real part) ; the imaginary part is the inverse QP lifetime
% define Green's function as electronic propagator
% explain what we do in the next subsection; define G, derive its equation of motion, get $G_2$, nested dependence on higher-order GFs hence : resum with a self-energy. To compute self-energy, we need a cycle of equations with vertex, polarization etc; approximate self-energy $\Sigma = GW$ to simplify the Hedin's equations 
% define screening
% derive GW
% Concept of QP and satellites
cite Strinati, Aryasetiawian, Martin Reining Ceperley, Julien Toulouse notes, Giustino, Stefanucci and van Leuween for the appendix  
Here I will write a general introduction for MBPT and an outline of the content of the following subsections. I would prefer to write it once the following is corrected and the content is fixed.

\subsection{Hedin's equations}
% First, define the Green's function
%\textcolor{red}{add more explanations, see Fulvio's thesis; especially correspondance between Schrödinger equation and GF}
We consider a system of N interacting electrons. We will consider the effect of nuclei motion in a later section.
We start from the Hamiltonian for interacting electrons in second quantization:
\begin{align}
\begin{split}
 	\hat{H} &= \int dx_1 \ \hpsidag(x_1) h(\rr_1) \hpsi(x_1) + \frac{1}{2} \iint dx_1 \  dx_2 \ \hpsidag(x_1) \hpsidag(x_2) v(\rr_1,\rr_2) \hpsi(x_2)\hpsi(x_1) \\
		&= \hat{H}_0 + \hat{H}_{int}.
\end{split}
\end{align}
where $\hat{\psi}(x)$ is a field operator in Schrödinger representation, $h$ is the single-particle Hamiltonian for non-interacting particles evolving in an external potential $V_{ext}$ and $v(\rr_1,\rr_2) = e^2 (\left| \rr_1 - \rr_2 \right|)^{-1}$ is the Coulomb interaction. In the above equation, x is the set of space and spin variables $x = (\rr, \sigma)$.
%

For the following derivation, we introduce an external potential $\Phi(x,x';t)$ which is local in time but nonlocal in space. We write it in the form of an interaction Hamiltonian :
\begin{equation}
	\hat{H}'(t) = \int dx dx' \hpsidag(x) \Phi(x,x';t) \hpsi(x') 
\end{equation}
In our case, this external perturbation will be set to 0 at the end of the calculation. It is a formal tool to derive the useful equations for the time-evolution of Green's functions. With this Hamiltonian, it is especially relevant to introduce the \textit{interaction picture}, in which both the operators and the wavefunctions have a time dependence. For the field operators we have :
\begin{equation}
	\hpsi(1) \equiv \hpsi(x_1, t_1) = e^{i\hat{H} t_1} \hpsi(x_1) e^{-i\hat{H} t_1}
\end{equation}
and for the interaction Hamiltonian :
\begin{equation}
	\hat{H}_I'(t) = e^{i\hat{H} t} \hat{H}'(t) e^{-i\hat{H} t} = \int dx dx' \hpsidag(x,t^+) U(x,x';t) \hpsi(x',t)
\end{equation}
where we use the notation $t^+$ for $t+\delta (\delta \to 0^+)$. We define a time-evolution operator in terms of this interaction Hamiltonian :
\begin{equation}
	\hat{S} = \exp\biggl\{ -i \int_{-\infty}^{+\infty} dt \hat{H}_I'(t) \biggr\}
\end{equation}
We now write the definitions of single- and two-particle Green's functions that include the dependence in $\Phi$ :
\begin{equation}
	G(1,2) = -i \frac{\bra{N}\hat{T}\left[\hat{S}\hpsi(1)\hpsidag(2)\right]\ket{N}}{\bra{N}T[\hat{S}]\ket{N}} \label{eq:GF}
\end{equation}
and
\begin{equation}
	G_2(1,2:1',2') = (-i)^2  \frac{\bra{N}\hat{T}\left[\hat{S}\hpsi(1)\hpsi(2)\hpsidag(2')\hpsidag(1')\right]\ket{N}}{\bra{N}T[\hat{S}]\ket{N}}\label{eq:2GF}
\end{equation}
where $\ket{N}$ is the exact ground state of the N-electron system and T is the Wick's time-ordering operator. It ensures that the time variable increases from right to left. It gives $\hat{T}\left[ \hpsi(\rr_1 t_1) \hpsidag(\rr_2 t_2) \right] = \theta(t_1 - t_2) \hpsi(\rr_1 t_1) \hpsidag(\rr_2 t_2) - \theta(t_2-t_1)\hpsidag(\rr_2 t_2)\hpsi(\rr_1 t_1)$, where $\theta$ is the Heaviside function. The physical meaning of the one-body Green's function is the probability amplitude that an electron added in the system at time $t_2$ and position $\rr_2$ propagates to position $\rr_1$ and time $t_1$. In the time-ordered formalism that we are using, it is also the probability amplitude that a hole created at time $t_1$ and position $x_1$ propagates to $(x_2,t_2)$, depending on how the two time variables are ordered.
%

We will now sketch a derivation for the equations of motion for the single-particle Green's function. To do this, we will make explicit the time dependence of each term in \ref{eq:GF}.
we start with the time evolution operator in the interaction picture, whose time dependence is :
\begin{equation}
	\hat{S}(t_a,t_b) = \exp	\biggl\{ -i \int_{t_a}^{t_b} dt \hat{H}_I'(t) \biggr\}
\end{equation}
and its time derivatives are:
\begin{align}
\begin{split}
	\frac{\partial}{\partial t_a} T[\hat{S}(t_a,t_b)] &= -i \hat{H}'_I(t_a)T[\hat{S}(t_a,t_b)] \\
	\frac{\partial}{\partial t_b} T[\hat{S}(t_a,t_b)] &= i T[\hat{S}(t_a,t_b)]\hat{H}'_I(t_b)
\end{split}
\end{align}
For the field operators, the derivation of the equations of motions can be found in Appendix \ref{app:EOM}. They read :
\begin{align}
\begin{split}
	\frac{\partial}{\partial t_1} \hpsi(1) &= -i \left[ h(1) + \int d3 v(1,3) \hpsidag(3)\hpsi(3) \right] \hpsi(1) \\
	\frac{\partial}{\partial t_2} \hpsidag(2) &= i \left[ h(2)\hpsidag(2) + \hpsidag(2) \int d3 v(2,3) \hpsidag(3)\hpsi(3) \right]
\end{split}	
\end{align}
where we introduced $v(1,2) = v(\rr_1,\rr_1)\delta(t_1-t_2)$ and $h(1)=h(\rr_1)$. Knowing that the derivative of the Heaviside function is a Dirac delta, we can write the equations of motion for the single-particle Green's functions :
\begin{align}
\begin{split}
	&\left[ i\frac{\partial}{\partial t_1} - h(1) \right] G_1(1,2) - \int d3 \Phi(1,3)G_1(3,2) + i \int d3 v(1,3) G_2(1,3^+;2,3^{++}) = \delta(1,2) \\
	&\left[ -i\frac{\partial}{\partial t_2} - h(2) \right] G_1(1,2) - \int d3 G_1(1,3)\Phi(3,2) + i \int d3 v(2,3) G_2(1,3^{--};2,3^-) = \delta(1,2)
\end{split}
\end{align}
with the notation : 
\begin{equation}
	\Phi(1,2) = \Phi(x_1,x_2;t_1) \delta(t_1-t_2).
\end{equation}
Here we notice that the equations for the single-particle Green's function depend on the two-particle Green's function. The latter could be expressed in terms of the three-body Green's function, and so on. Instead of using a hierarchy of higher-order Green's function, we will eliminate the two-particle Green's function from the equation and write a set of coupled integro-differential equations containing the self-energy and other useful quantities.
%

We use the functional derivative identity which is derived in appendix B \textcolor{red}{I don't know if it is necessary to include this derivation}:
\begin{equation}
	G_2(1,3;2,3^+) = G(1,2)G(3,3^+) - \frac{\delta G(1,2)}{\delta \Phi(3)} \label{eq:2GF_dPhi}
\end{equation}
where we consider the external potential to be local in space $\Phi(x_1,x_2;t_1) = \Phi(x_1,t_1)\delta(x_1,x_2)$. This restriction is enough to generate the equations of motion for the single-particle Green's function. For the two-particle ones instead, one needs to consider the more general form of the external potential, non-local in space.
The equations of motion become :
\begin{equation}
	\left[ i \frac{\partial}{\partial t_1} - h(1) - \Phi(1) + i \int d3 v(1,3)G(3,3^+) \right] G(1,2) - i \int d3 v(1^+,3) \frac{\delta G(1,2)}{\delta \Phi(3)} = \delta(1,2)
\end{equation}
and
\begin{equation}
	\left[ i \frac{\partial}{\partial t_2} - h(2) - \Phi(2) + i \int d3 v(2,3)G(3^-,3) \right] G(1,2) - i \int d3 v(2^-,3) \frac{\delta G(1,2)}{\delta \Phi(3)} = \delta(1,2)
\end{equation}
We cannot take the limit $\Phi \to 0$ yet because it would require the knowledge of the functional dependence of $G$ on $\Phi$. However we can rewrite the equations of motion (or at least one of them and the other would undergo the same process) by introducing new physical quantities, coupled in nonlinear self-consistent equations. 
%

The first of these quantities is the \textbf{total classical potential} $V$ : \textcolor{red}{\textsc{THE FIRST TERM IS THE HARTREE POTENTIAL} \textbf{BY THE WAY}}
\begin{equation}
	\vtot (1) \equiv \int d2 v(12) \langle \hat{n}(2) \rangle + \Phi(1) \label{eq:vtot}
\end{equation}
where $\hat{n}$ is the density operator. The equation of motion for the Green's function is then :
\begin{equation}
	\left[ i \frac{\partial}{\partial t_1} + \frac{1}{2}\nabla^2(1) - \vtot (1) -i\int d3 v(1^+,3) \frac{\delta}{\delta \Phi(3)} \right] G(1,2) = \delta(1,2) \label{eq:GF_EOM}
\end{equation}
To get rid of the functional derivative with respect to the external perturbation, we make use of the definition of the inverse Green's function and of the functional differentiation of a product:
\begin{equation}
	\frac{\delta G(1,2)}{\delta \Phi(3)} = - \int d45 G(1,4) \frac{\delta G^{-1}(4,5)}{\delta \Phi(3)} G(5,2)
\end{equation}
where the inverse single-particle Green's function is defined as :
\begin{equation}
	\int d3 G^{-1}(1,3) G(3,2) = \int d3 G(1,3)G^{-1}(3,2) = \delta(1,2) \label{eq:inv_GF}
\end{equation}
We now use the chain rule for functional differentiation :
\begin{equation}
	\frac{\delta G^{-1}(4,5)}{\delta \Phi(3)} = \int d6 \frac{\delta G^{-1}(4,5)}{\delta \vtot(6)} \frac{\delta \vtot(6)}{\delta \Phi(3)}
\end{equation}
We introduce the \textbf{scalar vertex function}, a three-point quantity defined as :
\begin{equation}
	\Gamma(1,2;3) \equiv -\frac{\delta G^{-1}(1,2)}{\delta \vtot(3)} \label{eq:vertex}
\end{equation}
We introduce the \textbf{inverse dielectric matrix} $\inveps$ :
\begin{equation}
	\inveps(1,2) = \frac{\delta \vtot(1)}{\delta \Phi(2)}.
\end{equation} 
It is the many-body formulation of the classical (inverse) dielectric matrix. 
We introduce the \textbf{dynamically screened interaction} $W$ or screened Coulomb interaction, defined as :
\begin{equation}
	W(1,2) \equiv \int d3 \inveps(1,3) v(3,2) \equiv \int d3 v(1,3) \inveps(2,3)
\end{equation}
Note that the screened interaction is symmetric under the exchange of indices $W(1,2) = W(2,1)$.
Finally, we introduce the \textbf{electron self-energy}, defined as :
\begin{equation}
	\Sigma(1,2) = i \int d34 G(1,3) \Gamma(3,2;4) W(4,1^+)
\end{equation}
%

With these quantities, we can rewrite the equation of motion for the single-particle Green's function :
\begin{equation}
	\left[ i \frac{\partial}{\partial t_1} + \frac{1}{2}\nabla^2(1) - \vtot (1)\right] G(1,2) - \int d3 \Sigma(1,3) G(3,2) = \delta(1,2) \label{eq:GF_EOM_SE}
\end{equation}
We can see here that the self-energy $\Sigma$ has the meaning of a nonlocal and energy-dependent effective single-particle potential.
%

Using eqs. \eqref{eq:vertex} and \eqref{eq:GF_EOM_SE}, we can express the vertex function in terms of the above quantities. 
\begin{equation}
	\Gamma(1,2;3) = \delta(1,2) \delta(1,3) + \int d4567 \frac{\delta \Sigma(1,2)}{\delta G(4,5)} G(4,6) G(7,5) \Gamma(6,7;3). \label{eq:vertex_hedin}
\end{equation}
More details about these quantities and their derivations can be found for example in Strinati's review\cite{strinati1988application}.
The previous quantities form a set of coupled integro-differential equations. In order to close the loop and build a self-consistent set, we need to write the relations between $W$ and the other quantities. By combining $\vtot$, $\inveps$ and $W$, we get :
\begin{equation}
	W(1,2) = v(1,2) + \int d34 v(1,3) \frac{\delta \langle \hat{n}(3)\rangle}{\delta \vtot (4)} W(4,2)
\end{equation}
We define the \textbf{irreducible polarizability} to be :
\begin{equation}
	P(1,2) \equiv \frac{\delta \langle \hat{n}(1)\rangle}{\delta \vtot (2)}. \label{eq:P_dn/dV}
\end{equation}
The reducible polarizability would be the derivative of the density with respect to the perturbation $\Phi$. With the following relation 
\begin{equation}
	n(1) = \langle \hat{n}(1)\rangle = -iG(1,1+),
\end{equation}
and using properties of the inverse Green's function and the chain rule, one can write :
\begin{align}
\begin{split}
	P(1,2) &= -i \frac{\delta G(1,1+)}{\delta V(2)} = i \int d34 G(1,3)\frac{\delta G^{-1}(3,4)}{\delta V(2)}G(4,1^+)\\
	&= -i \int d34 G(1,3) G(4,1^+) \Gamma(3,4;2)
\end{split}
\end{align}
Then we can write the screened interaction in term of $P$ :
\begin{equation}
	W(1,2) = v(1,2) + \int d34v(1,3)P(3,4) W(4,2)
\end{equation}
as well as the dielectric matrix :
\begin{equation}
	\epsilon(1,2) = \delta(1,2) - \int d3 v(1,3) P(3,2)
\end{equation}
We now have a set of coupled self-consistent equations, where the limit $\Phi \to 0$ can be taken. 
%

\subsection{Dyson equation}

In order to be able to compute the Green's function and the related useful quantities, we need to reformulate the Green's function. We start by separating the part which comes only from the one-particle operators in the equation of motion \eqref{eq:GF_EOM_SE} :
\begin{equation}
	\left[ i\frac{\partial}{\partial t_1} - h(1) \right] G_0(1,2) = \delta(1,2)
\end{equation}
This is the definition of the non-interacting Green's function $G_0$. It also has an inverse and they obey the same relation as the full single-particle Green's function \eqref{eq:inv_GF}, therefore one can write :
\begin{equation}
	G(1,2) = \int d34 G_0(1,4)G^{-1}_0(4,3)G(3,2)
\end{equation}
Inserting the above equation in \eqref{eq:GF_EOM_SE}, we get :
\begin{equation}
	\int d3 \left[ G_0^{-1}(1,3) - \Sigma(1,3) \right] G(3,2) = \delta(1,2).
\end{equation}
After multiplying the from the left by $\int d1 G_0(4,1)$ we obtain :
\begin{equation}
	G(1,2) = G_0(1,2) + \int d34 G_0(1,3) \Sigma(3,4) G(4,2) \label{eq:Dyson}
\end{equation}
or equivalently,
\begin{equation}
	G^{-1}(1,2) = G_0^{-1}(1,2) - \Sigma(1,2)
\end{equation}
Equation \eqref{eq:Dyson} is called the \textit{Dyson equation} for the single-particle Green's function. Knowing $G_0$, which is numerically simple to compute, and approximating the self-energy $\Sigma$, which we will discuss later, allows one to compute the Green's function $G$.
\textcolor{pink}{The vertex function contains a local part which give the Hartree-Fock self-energy. The other term are the vertex corrections. Neglecting the vertex corrections in the polarizability leads to the RPA.\textcolor{red}{DO A PARAGRAPH ON THIS}. Neglecting the vertex corrections in the self-energy leads to the GWA.}

\subsection{The $\mathbf{GW}$ approximation}
With the Dyson equation for the Green's function, we can now complete the set of self-consistent, coupled equations that are called the \textit{Hedin's equations}:
\begin{empheq}[box=\widefbox]{align*}
	&\Sigma(1,2) = i \int d34 G(1,3) \Gamma(3,2;4) W(4,1^+) \\
	&G(1,2) = G_0(1,2) + \int d34 G_0(1,3) \Sigma(3,4) G(4,2) \\
	&\Gamma(1,2;3) = \delta(1,2) \delta(1,3) + \int d4567 \frac{\delta \Sigma(1,2)}{\delta G(4,5)} G(4,6) G(7,5) \Gamma(6,7;3) \\
	&P(1,2) = -i \int d34 G(1,3) G(4,1^+) \Gamma(3,4;2) \\
	&W(1,2) = v(1,2) + \int d34v(1,3)P(3,4) W(4,2)
\end{empheq}
$\Gamma$ and $W$ also satisfy Dyson equations, just as $G$.This is an exact set of coupled equations, that is solved self-consistently. In practice, it is untractable to solve. One has to chose a starting approximation for the self-energy, which contains the summation to all orders in the interaction expansion of $G$. One way to approximate the self-energy is to consider $\frac{\delta \Sigma(12)}{\delta G(4,5)} = 0$ so that $\Gamma = \delta(1,2)\delta(1,3)$ and we obtain :
\begin{equation} 
\gS(1,2) = iG(1,2)W(1,2). \label{eq:GW}
\end{equation}
This is the so-called $GW$ approximation, which gives good results for weakly-correlated materials. It is the first-order in the expansion of the self-energy in terms of the interaction $W$. All higher order terms that are involved in electronic correlations are neglected. Part of those can be included by recomputing $G$ self-consistently with the Hedin's equations. However in practice, it is not guaranteed that it leads to better results. Most of the times, the $GW$ method is a one-shot calculation starting from the DFT Kohn-Sham eigenvalues and wave functions, as we will see in a later subsection. 

Eq. \eqref{eq:GW} resembles the Hartree-Fock approximation, where the exchange part of the self-energy is written as $\gS_x^{HF}(1,2) = i G(1,2^+)v(1,2)$.
The difference in this case is that we used the dynamically screened interaction instead of the bare Coulomb one. 


\subsection{Quasiparticle equations}
Once the limit $\Phi \to 0$ is taken, there is no time-dependent potential acting on the system of N electrons. Hence, the system is invariant under time translation and the Green's function depends only on the time difference $\tau = t_1 - t_2$. One can do the Fourier transform from time $\tau$ to frequency $\omega$, and we can write the Green's function in the so-called Lehmann representation :
\begin{equation}
	G(x_1,x_2;\omega) = \sum_a \frac{f_a(x_1)f_a^*(x_2)}{\omega-\varepsilon_a + i\eta} + \sum_i \frac{f_i(x_1)f_i^*(x_2)}{\omega-\varepsilon_i + i\eta}
\end{equation}
where $a,i$ denote electron states, $f_a(x) = \bra{N}\hpsi(x)\ket{N+1,a}$ and $f_i(x) = \bra{N-1,i} \hpsi(x) \ket{N}$ are the Lehmann amplitudes (as called Dyson orbitals). They are defined with the $N$-electron ground state $\ket{N}$ whose total energy is $E_N$, the electron state number $a$ of the $(N+1)$-electron system $\ket{N+1,a}$ with total energy $E_{N+1,a}$ and the electron-state number $i$ of the $(N-1)$-electron system $\ket{N-1,i}$ with total energy $E_{N-1,i}$.
The Lehmann representation of the Green's function also contains the quasiparticle energies, which are defined as $\varepsilon_a = E_{N+1,a} - E_N = -A_a$ and $\varepsilon_i = E_N - E_{N-1,i} = -I_i$. $A_a$ and $I_i$ are the electron affinities and ionization energies. This highlights the link between the poles of the Green's function from many-body perturbation theory and the photoemission and inverse photoemission spectroscopies. 

With this form of the Green's function we can reformulate the Dyson equation \eqref{eq:Dyson}. Just as the Green's function, the self-energy depends only on the time difference $\tau = t_1 - t_2$. We can then take the Fourier transform of eq. \eqref{eq:GF_EOM_SE} :
\begin{equation}
	\left[ \omega - h(\rr_1) \right] G(x_1,x_2;\omega) - \int dx_3 \Sigma(x_1,x_2;\omega) G(x_3,x_2;\omega) = \delta(x_1,x_2)
\end{equation}
Inserting the Lehmann representation of $G(x_1,x_2;\omega)$, one can select the term corresponding to a given pole $\varepsilon_n$ by multiplying the equation by $\omega - \varepsilon_n$ and taking the limit $\omega \to \varepsilon_n$, giving :
\begin{equation}
	\left[ \varepsilon_n - h(\rr_1) \right] f_n(x_1)f^*_n(x_2) - \int dx_3 \Sigma(x_1,x_3;\varepsilon_n) f_n(x_3) = \varepsilon_n f_n(x_1)
\end{equation}
and we obtain an eigenvalue equation :
\begin{equation}
	h(\rr_1)f_n(x_1) + \int dx_3 \Sigma(x_1,x_3;\varepsilon_n)f_n(x_3) = \varepsilon_n f_n(x_1)
\end{equation}
These are the \textit{quasiparticle equations}. They give the quasiparticle energies and the Lehmann amplitudes, or also called the Dyson orbitals. The quasiparticle energies are in general complex, and the Lehmann amplitudes, which act as the quasiparticles wavefunctions, are not orthogonal because $\Sigma$ is energy-dependent and non Hermitian. The physical meaning of the poles of $G$ is therefore the exact excitation energies of the $N\pm1$ electrons. In an infinite, periodic system, the poles form a branch cut, and we can interpret the excitation spectrum in terms of quasiparticles with energies $\Re\varepsilon_n$ and life-times $1/\Im\varepsilon_n$
Here it is made apparent that $\Sigma$ is a nonlocal, energy-dependent single-particle effective potential. One thing to notice is also the fact that the quasiparticle energy is made out of the bare, independent single particle, and another term coming from the interaction with surrounding particle. The quasiparticle is the bare particle "dressed" with the interaction.
Since $\gS$ is frequency-dependent, so are the quasiparticle energies. To solve this in practice, we linearize the self-energy :
\begin{equation}
	\varepsilon_n = \varepsilon^{KS}_n + Z_n\Re\Sigma(\varepsilon^{KS}_n)
\end{equation} 
where $\varepsilon^{KS}_n$ are Kohn-Sham eigenvalues and the renormalization factor $Z$ is defined as :
\begin{equation}
	Z_n \equiv \left[ 1 - \frac{\partial \gS(\omega)}{\partial \omega} \left. \right\vert_{\omega = \varepsilon_n} \right]^{-1}
\end{equation}
It is a measure of the single-particle character of the system. If $Z=1$, the electron addition or removal spectra (given by $\Im G$) shows a single peak at the quasiparticle energy. The width of the peak is proportional to the inverse of the life-time of the single-particle state. For weakly correlated system, typically $Z \leq 1$. In this case, the intensity of the quasiparticle peak is renormalized by $Z$, and the amount missing is transferred to secondary peaks called satellites. In the $GW$ approximation, there is a only one satellite, and it is at the wrong energy with respect to experiments. This is because the electronic correlations are approximated. Finally if $Z \ll 1$, it means that the material is not well described by a single-particle scheme, for example because of strong correlations. In this case, Many Body Perturbation Theory is not well suited to describe such materials.

%\textcolor{green}{At some point, talk about the Hartree part in the self-energy.}
\subsection{The Bethe-Salpeter equation}

The $GW$ approximation allows us to compute the quasiparticle energies through the addition or removal of one particle. These excitations are qualified as charged. Instead, optical excitations in semiconductors are referred to as neutral excitations, where an electron is promoted to a conduction band but stays in the crystal, and leaves a hole in a valence band. In order to have a good description of these phenomena, we need to consider the interaction between the excited electron and the hole. In principle, this interaction is contained in the vertex function $\Gamma$ from eq. \eqref{eq:vertex_hedin}. However, we neglected it in the $GW$ approximation. In this section, we will see how to include the electron-hole interaction from the two-particle Green's function, and how we can change the formulation of the problem from particles in bands to a new type of quasiparticle : the \textit{exciton}, which is a bound electron-hole pair.

\subsubsection{Dyson equation for the two-particle propagator $\mathbf{L}$}
We start by writing a Dyson equation for the two-particle Green's function, defined in eq. \eqref{eq:2GF}.  We define the two-particle correlation function or propagator $L$ :
\begin{equation}
	L(1,2,1',2') = - G_2(1,2,1',2') + G(1,1')G(2,2') \label{eq:L}
\end{equation}
It contains the correlated propagation of a particle and a hole which is the first term, and the second term removes the uncorrelated propagation of the two. Depending on the time-ordering of the field operators in the definitions of $G$ and $G_2$, one can have different combinations for the two particles, for instance hole-hole, electron-electron \textit{etc}.
By using the identity in eq. \eqref{eq:2GF_dPhi}, with a fully non-local external potential $\Phi(2',2)$, we can also write :
\begin{equation}
	L(1,2,1',2') = \frac{\delta G(1,1')}{\delta \Phi(2',2)} = -\int d33' G(1,3)\frac{\delta G^{-1}(3,3')}{\delta\Phi(2',2)}G(3',1')
\end{equation}
After computing the functional derivative of the inverse Green's function, we get :
\begin{equation}
	L(1,2,1',2') = G(1,2')G(2,1') + \int d33' G(1,3) \frac{\delta \Sigma(3,3')}{\delta \Phi(2',2)} G(3',1') \label{eq:L_}
\end{equation}
\textcolor{green}{please act as if I had defined $\gS = v_H + \gS_{xc}$ and detailled each term above in the GW section} with $\gS = v_H + \gS_{xc}$.  \textcolor{green}{please act as if $v_H$ was defined above in the GW section} One can take the limit $\Phi \to 0$ in the above equation to obtain the equilibrium solution. The first term in eq. \eqref{eq:L_} is defined as the propagator for two independent particles :
\begin{equation}
	L_0(1,2,1',2') = G(1,2') G(2,1') 
\end{equation}
We can use the chain rule for the functional derivative of $\gS$ to express it with respect to $G$. Now if we define the two-particle interaction $i\Xi$ as :
\begin{equation}
	\Xi(3,2,3',2') \equiv -i \delta(3,3')\delta(2'^+,2)v(3^+,2) + \frac{\delta \gS_{xc}(3,3')}{\delta(2',2)}
\end{equation}
then we obtain the \textbf{Bethe-Salpeter equation} :
\begin{equation}
	L(1,2,1',2') = L_0(1,2,1',2') + \int d3'3d44' L_0(1,3',1',3) \Xi(3,4,3',4') L(4',2,4,2')
\end{equation}
which is a Dyson equation for the two-particle propagator L. The two-particle interaction quantity $\Xi$ is called the \textit{kernel}. It contains two terms, which we can separate and hence break the \gls{BSE} into the so-called irreducible contribution, that does not contain the derivative of the Hartree potential $v_H$ :
\begin{equation}
	\tilde{L}(1,2,1',2') = L_0(1,2,1',2') + \int d33'd44' L_0(1,3',1',3) \frac{\delta \gS_{xc}(3,3')}{\delta(2',2)} L(4',2,4,2')
\end{equation} 
and 
\begin{equation}
	L(1,2,1',2') = \tilde{L}(1,2,1',2') -i \int d34 \tilde{L}(1,3,1',3) v(3^+,4) L(4,2,4^+,2')
\end{equation}
Now, from the first identity in eq. \eqref{eq:L}, we have that $L$ is the variation of $G$ under the action of a non-local potential $\Phi$. If we define $v_H(2',2) \equiv \delta(2',2)v_H(1)$, then we can extend our total classical potential $\vtot$ from eq. \eqref{eq:vtot} to be non-local, and we can express the irreducible two-particle propagator as :
\begin{equation}
	\tilde{L}(1,2,1',2') = \frac{\delta G(1,1')}{\delta \vtot(2',2)}
\end{equation}
With this equation, we can notice the similarity with eq. \eqref{eq:P_dn/dV}, where the density is replaced by the Green's function and the total classical potential is non-local. In fact, the irreducible two-particle propagator $\tilde{L}$ is a generalization of the irreducible polarizability to four points. We have the relation :
\begin{equation}
	-i \tilde{L}(1,2,1^+,2^+) = P(1,2) 
\end{equation}
The same relation exists for the full or reducible polarizability, which we call $\chi$, and the reducible two-particle propagator :
\begin{equation}
	\chi(1,2) = \frac{n(1)}{\delta \Phi(2)} = -i L(1,2,1^+,2^+)
\end{equation}
In the two above equations, the time-ordering is chosen so that the two-particle propagator (reducible or irreducible) describes the propagation of an electron correlated with a hole.

\subsubsection{The Bethe-Salpeter equation in the $\mathbf{GW}$ approximation}
In the same way we needed an approximation to compute the electron self-energy $\gS$, we need an approximation to be able to compute the kernel $\Xi$ and hence the Dyson equation for $L$. The main difficulty in solving the \gls{BSE} is that the kernel is a four-points quantity. In principle, the arguments are in spin-space-time coordinates. In the following, we will omit the spin dependence. The two-particle propagators depend on four times or three time differences, in the absence of a time-dependent Hamiltonian. We can Fourier transform the BSE, which will therefore depend on three frequencies. If we consider only the simultaneous propagation of an electron and a hole, we obtain :
\begin{equation}
	L(\go_1,\go_2) = L_0(\go_1,\go_2) + \int d\go_3 d\go_4 \frac{L_0(\go_1,\go_2,\go_3)}{(2\pi)^2} \Xi(\omega_1,\go_3,\go_4) L(\go_1,\go_4) \label{eq:BSE_freq}
\end{equation}
For more details about this derivation and the relation between the Green's functions in frequency space, I refer to section 14 of \cite{martin2016interacting}. We set ourselves in the $GW$ approximation, which will simplify the calculation of the kernel $\Xi$. The exchange-correlation part reads :
\begin{equation}
	\Xi^{GWA}_{xc}(1,2,3,4) = i\delta(1,4)\delta(2,3)W(1,2) + iG(1,3)\frac{\delta W(1,3)}{\delta G(4,2)}
\end{equation}
The first term is at first order in $W$. The second term is the change in the screening when the system is perturbed, and contains higher-orders in $W$. In accordance with the $GW$ approximation, we also neglect here the second term in the above equation. In frequency space, we are left with :
\begin{equation}
	\Xi^{GWA}_{xc}(\go_1,\go_2,\go_3) \approx iW(\go_2 - \go_3)
\end{equation}
Here we see that the coupling between two particles, which comes from the screened interaction, is frequency-dependent. It originates from the fact that the system needs time to adapt to the perturbation, which is the creation of the electron-hole pair. Another important approximation that we introduce here is that we consider the screened interaction to be static, \textit{ie} frequency-independent : $W(\go) \to W(0)$. In practice, we obtain $L_0$ with the single-particle Green's functions in the quasiparticle approximation in the dynamic \gls{GWA}, and we use a static screening only for the kernel of the \gls{BSE}. Reintroducing the space and (implicit) spin dependence, we finally obtain :
\begin{align}
\begin{split}
	L(x_1,x_2,x_{1'},x_{2'};\go) = &L_0(x_1,x_2,x_{1'},x_{2'};\go) \\
	    &-i \int dx_3dx_4 L_0(x_1,x_3,x_{1'},x_{3};\go) v(x_3,x_4) L(x_4,x_2,x_{4},x_{2'};\go) \\
		&\qquad - L_0(x_1,x_4,x_{1'},x_{3};\go) W(x_3,x_4)  L(x_3,x_2,x_{4},x_{2'};\go) \label{eq:GW-BSE}
\end{split}
\end{align}

\subsubsection{Reformulation in a two-particle Schrödinger equation}
With the \gls{BSE} written in this form, we can now reformulate the problem into a Schrödinger equation for two particles, which will highlight the physics of the problem and make appear the \textit{excitons} as emerging quasiparticles. Here we assume that the non-interacting two-particle propagator $L_0$ is diagonal in an independent-particle basis, and that we obtained the quasiparticle eigenvalues from the \gls{GWA}. At $T=0$, we can write :
\begin{equation}
	L_{0\ n_1n_2n_3n_4}(\go) = L_{0\ n_1n_3}^{n_4n_2} = 2 i \frac{(f_{n_1} - f_{n_2}) \delta_{n_1n_4}\delta_{n_2n_3}}{\go - (\varepsilon_1 - \varepsilon_2) \pm i\eta}
\end{equation}
where the $n_i$ indices denote for the quasiparticle state with occupation number $f_i$ and the factor 2 in the right-hand side stems from the summation on spin indices. The plus or minus sign in the denominator depends on the sign of the difference of the occupation factors $f_i$. The \gls{BSE} becomes :
\begin{equation}
	L_{n_1n_3}^{n_4n_2} = \left[ L_0^{-1} + \frac{i}{2}\Xi\right]^{-1\ n_4n_2}_{n_1n_3} = 2i \left[ H^{2p} - \mathbb{I}(\omega \pm i\eta) \right]^{-1\ n_4n_2}_{n_1n_3}(f_{n_2} - f_{n_4}),
\end{equation}
where $\mathbb{I}$ is the identity matrix and $H^{2p}$ is the two-particle Hamiltonian 
\begin{equation}
	H^{2p\ n_4n_2}_{n_1n_3} = (\varepsilon_{n_2} - \varepsilon_{n_1}) \delta_{n_1n_4}\delta_{n_2n_3} + (f_{n_1} - f_{n_3}) \Xi_{n_1n_3}^{n_4n_2}.
\end{equation}
The matrix element of the kernel is :
\begin{equation}
	\Xi_{n_1n_3}^{n_4n_2} = 2v_{n_1n_4}^{n_3n_2} - W_{n_1n_3}^{n_4n_2}
\end{equation}
We consider a semiconductor or an insulator with well-separated valence and conduction bands. The difference of the occupation factors, at $T=0$, in the above equations guarantees that only pairs of an occupied and an empty state are contributing in the interaction. We can use the indices $v,c$ for valence and conduction states, respectively. Then
\begin{equation}
	\Xi^{v'c'}_{vc} = 2v^{cc'}_{vv'} - W^{v'c'}_{vc}
\end{equation}
We can remark that the matrix elements of the bare Coulomb interaction are coupling two different dipoles together. This corresponding contribution is often referred to as electron-hole exchange. The second term is called the direct electron-hole interaction, and it is an attractive interaction between the electron and the hole that binds them in a pair.
We can decompose the Hamiltonian into four blocks :
\begin{equation}
	H^{2p} = \begin{pmatrix}
		H^{res} & H^{coupl} \\
		-[H^{coupl}]^* & H^{ares}
	\end{pmatrix}
\end{equation}
where the resonant part is 
\begin{equation}
	H^{res} \equiv H^{2p\ v'c'}_{vc} = (\varepsilon_c - \varepsilon_v) \delta_{vv'}\delta_{cc'} + \Xi^{v'c'}_{vc}
\end{equation}
This subpart is hermitian and corresponds to transitions from the valence to the conduction band, with positive frequencies. The coupling part is :
\begin{equation}
	H^{coupl} \equiv H^{2p\ c'v'}_{vc} = \Xi^{c'v'}_{vc} = [\Xi^{v'c'}_{cv}]^*
\end{equation}
which is symmetric. The antiresonant part is :
\begin{equation}
	H^{ares} \equiv H^{2p\ c'v'}_{vc} (\varepsilon_v - \varepsilon_c)\delta_{vv'}\delta_{cc'} - \Xi^{c'v'}_{cv} = - [H^{res}]^*
\end{equation}
The whole Hamiltonian $H^{2p}$ is not hermitian, so in general it has complex eigenvalues. For the calculations in this thesis, we used the Tamm-Dancoff approximation, which consists in neglecting the coupling part of the Hamiltonian. It works best with bulk semiconductors and insulators, where the energy of the transitions is large compared to the interaction matrix elements in $H^{coupl}$. With this approximation, we only consider transitions with positive energies, and the full Hamiltonian becomes hermitian.
With this Hamiltonian, we can build a two-particle Schrödinger equation :
\begin{equation}
	\sum_{n_3n_4} H^{2p\ n_3n_4}_{n_1n_2} A_\lambda^{n_3n_4} = E_\lambda A_\lambda^{n_1n_2}
\end{equation}
where $E_\lambda$ are the eigenvalues of the \textit{excitons} $\lambda$. We change from the quasiparticle basis $\{n\}$ to the transition basis $\{\lambda\}$, and $A_\lambda$ are the coefficients of the expansion in the transition basis. We will see in a later section that they are also related to the oscillator strength of the transitions. We can write the two-particle propagator using these quantities :
\begin{equation}
	L^{n_3n_4}_{n_1n_2}(\go) = 2i \sum_{\gl\gl'}\frac{A^{n_1n_2}_\gl \ I^{-1}_{\gl\gl'} \ A^{*n_3n_4}_{\gl'}}{\omega - E_\gl + i\eta} (f_{n_4} - f_{n_3})
\end{equation}
with the overlap matrix defined as 
\begin{equation}
	I_{\gl\gl'} \equiv \sum_{n_1n_2} A^{*n_1n_2}_{\gl} A^{n_1n_2}_{\gl'}.
\end{equation}
Each couple $(nn')$ corresponds to a pair $(vc)$ or $(cv)$ of an occupied and an empty state. We remark that the exciton energies replaced the difference of quasiparticle energies $\varepsilon_c - \varepsilon_v$ in the denominator, which is the quasiparticle gap. The screened interaction contributes to the attraction between the electron and the hole, lowering the transition energy below the gap. The difference between the transition energy and the quasiparticle gap is called the \textit{exciton binding energy}. Excitonic effects can be extremely important in the optical properties of semiconductors, as we will see in the next section.



\section{Optics}
I plan to write a section about the optics. transition dipoles, linear response, absorption spectra, luminescence, etc

\section{Numerical implementation / Computational scheme}
Maybe this can go in the next chapter about the methods
%There are different ways of treating the frequency dependence of the screening. One can the dielectric matrix on a selected grid of frequencies $\omega$, or approximate it with a model function depending on a few frequencies, as in the Plasmon Pole Approximation. Most commonly, it is computed in the \gls{RPA}. 
Subtract the $v_{xc}$ from DFT when computing QP energies
from $\rr$ space to $\kk$ space, dipoles, Lehmann representation from DFT ev and wf
